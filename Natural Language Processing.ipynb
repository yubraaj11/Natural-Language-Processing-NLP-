{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f1ede7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3392074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yubra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') #punkt library for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "509a322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\" There are a number of reasons you may need a block of text and when you do, a random paragraph can be the perfect solution. If you happen to be a web designer and you need some random text to show in your layout, a random paragraph can be an excellent way to do this. If you're a programmer and you need random text to test the program, using these paragraphs can be the perfect way to do this. Anyone who's in search of realistic text for a project can use one or more of these random paragraphs to fill their need.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2aee1a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' There are a number of reasons you may need a block of text and when you do, a random paragraph can be the perfect solution.',\n",
       " 'If you happen to be a web designer and you need some random text to show in your layout, a random paragraph can be an excellent way to do this.',\n",
       " \"If you're a programmer and you need random text to test the program, using these paragraphs can be the perfect way to do this.\",\n",
       " \"Anyone who's in search of realistic text for a project can use one or more of these random paragraphs to fill their need.\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df8f083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There',\n",
       " 'are',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'reasons',\n",
       " 'you',\n",
       " 'may',\n",
       " 'need',\n",
       " 'a',\n",
       " 'block',\n",
       " 'of',\n",
       " 'text',\n",
       " 'and',\n",
       " 'when',\n",
       " 'you',\n",
       " 'do',\n",
       " ',',\n",
       " 'a',\n",
       " 'random',\n",
       " 'paragraph',\n",
       " 'can',\n",
       " 'be',\n",
       " 'the',\n",
       " 'perfect',\n",
       " 'solution',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'happen',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'web',\n",
       " 'designer',\n",
       " 'and',\n",
       " 'you',\n",
       " 'need',\n",
       " 'some',\n",
       " 'random',\n",
       " 'text',\n",
       " 'to',\n",
       " 'show',\n",
       " 'in',\n",
       " 'your',\n",
       " 'layout',\n",
       " ',',\n",
       " 'a',\n",
       " 'random',\n",
       " 'paragraph',\n",
       " 'can',\n",
       " 'be',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'way',\n",
       " 'to',\n",
       " 'do',\n",
       " 'this',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " \"'re\",\n",
       " 'a',\n",
       " 'programmer',\n",
       " 'and',\n",
       " 'you',\n",
       " 'need',\n",
       " 'random',\n",
       " 'text',\n",
       " 'to',\n",
       " 'test',\n",
       " 'the',\n",
       " 'program',\n",
       " ',',\n",
       " 'using',\n",
       " 'these',\n",
       " 'paragraphs',\n",
       " 'can',\n",
       " 'be',\n",
       " 'the',\n",
       " 'perfect',\n",
       " 'way',\n",
       " 'to',\n",
       " 'do',\n",
       " 'this',\n",
       " '.',\n",
       " 'Anyone',\n",
       " 'who',\n",
       " \"'s\",\n",
       " 'in',\n",
       " 'search',\n",
       " 'of',\n",
       " 'realistic',\n",
       " 'text',\n",
       " 'for',\n",
       " 'a',\n",
       " 'project',\n",
       " 'can',\n",
       " 'use',\n",
       " 'one',\n",
       " 'or',\n",
       " 'more',\n",
       " 'of',\n",
       " 'these',\n",
       " 'random',\n",
       " 'paragraphs',\n",
       " 'to',\n",
       " 'fill',\n",
       " 'their',\n",
       " 'need',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(paragraph)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1fc3c",
   "metadata": {},
   "source": [
    "## Stemming and Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98a1ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8fad2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43e9f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('English'))]       #set is used to get stopwords of particular language \n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0d34ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there number reason may need block text , random paragraph perfect solut .',\n",
       " 'if happen web design need random text show layout , random paragraph excel way .',\n",
       " \"if 're programm need random text test program , use paragraph perfect way .\",\n",
       " \"anyon 's search realist text project use one random paragraph fill need .\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffe7f4",
   "metadata": {},
   "source": [
    "## Lemmatization \n",
    "\n",
    "\n",
    "<br> Problem with stemming: \n",
    "`\n",
    "it produce intermediate representation of word that may not have any meaning\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22aa639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yubra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yubra\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "930930f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ccbd25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d37ae81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lemm = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cb09f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentence_lemm)):\n",
    "    words = nltk.word_tokenize(sentence_lemm[i])\n",
    "    words = [lemmetizer.lemmatize(word) for word in words if word not in set(stopwords.words('English'))]\n",
    "    sentence_lemm[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75ae840e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There number reason may need block text , random paragraph perfect solution .',\n",
       " 'If happen web designer need random text show layout , random paragraph excellent way .',\n",
       " \"If 're programmer need random text test program , using paragraph perfect way .\",\n",
       " \"Anyone 's search realistic text project use one random paragraph fill need .\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_lemm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b12310",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6114c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "545dbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f440933",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbf4a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmetizer.lemmatize(word) for word in review if word not in set(stopwords.words('English'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6cceb5",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "    - Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f3a923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "726efad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10368bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11f00fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102403f",
   "metadata": {},
   "source": [
    "## TF-IDF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8aa1eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00d58e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88ad36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tfidf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8366cea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.38602079, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.38602079, 0.20144166, 0.38602079,\n",
       "        0.        , 0.20144166, 0.30434322, 0.        , 0.        ,\n",
       "        0.        , 0.20144166, 0.        , 0.38602079, 0.        ,\n",
       "        0.        , 0.38602079, 0.        , 0.20144166, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.34243719, 0.34243719, 0.        ,\n",
       "        0.34243719, 0.34243719, 0.        , 0.17869793, 0.        ,\n",
       "        0.        , 0.17869793, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.35739586, 0.        , 0.        , 0.        ,\n",
       "        0.34243719, 0.        , 0.        , 0.17869793, 0.        ,\n",
       "        0.        , 0.26998141, 0.34243719],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20737309, 0.        ,\n",
       "        0.        , 0.20737309, 0.31330457, 0.39738712, 0.39738712,\n",
       "        0.        , 0.20737309, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.39738712, 0.20737309, 0.        ,\n",
       "        0.39738712, 0.31330457, 0.        ],\n",
       "       [0.35159705, 0.        , 0.        , 0.        , 0.35159705,\n",
       "        0.        , 0.        , 0.        , 0.18347793, 0.        ,\n",
       "        0.35159705, 0.18347793, 0.        , 0.        , 0.        ,\n",
       "        0.35159705, 0.18347793, 0.35159705, 0.        , 0.35159705,\n",
       "        0.        , 0.        , 0.        , 0.18347793, 0.35159705,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0812292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
